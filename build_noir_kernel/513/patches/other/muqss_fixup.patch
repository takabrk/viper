From 6697f13cfb232e5b86a4fca339636bea245d0ff3 Mon Sep 17 00:00:00 2001
From: Your Name <you@example.com>
Date: Sat, 17 Jul 2021 02:41:42 +0200
Subject: [PATCH] fixup

---
 kernel/sched/idle.c  |  2 +-
 kernel/sched/sched.h | 43 +++++++++++++++++++++++++++++++------------
 kernel/sched/stats.h | 10 ++++++++++
 3 files changed, 42 insertions(+), 13 deletions(-)

diff --git a/kernel/sched/idle.c b/kernel/sched/idle.c
index 2ed8f5ae4..2145ee887 100644
--- a/kernel/sched/idle.c
+++ b/kernel/sched/idle.c
@@ -265,7 +265,7 @@ static void do_idle(void)
 	/*
 	 * Check if we need to update blocked load
 	 */
-	nohz_run_idle_balance(cpu);
+	nohz_balance_enter_idle(cpu);
 
 	/*
 	 * If the arch has a polling bit, we maintain an invariant:
diff --git a/kernel/sched/sched.h b/kernel/sched/sched.h
index 90dfbe0df..97fc7049c 100644
--- a/kernel/sched/sched.h
+++ b/kernel/sched/sched.h
@@ -2,6 +2,15 @@
 /*
  * Scheduler internal types and methods:
  */
+
+#ifdef CONFIG_SCHED_DEBUG
+void update_sched_domain_debugfs(void);
+#else
+static inline void update_sched_domain_debugfs(void)
+{
+}
+#endif
+
 #ifdef CONFIG_SCHED_MUQSS
 #include "MuQSS.h"
 
@@ -1571,18 +1580,6 @@ static inline unsigned int group_first_cpu(struct sched_group *group)
 
 extern int group_balance_cpu(struct sched_group *sg);
 
-#ifdef CONFIG_SCHED_DEBUG
-void update_sched_domain_debugfs(void);
-void dirty_sched_domain_sysctl(int cpu);
-#else
-static inline void update_sched_domain_debugfs(void)
-{
-}
-static inline void dirty_sched_domain_sysctl(int cpu)
-{
-}
-#endif
-
 extern int sched_update_scaling(void);
 
 extern void flush_smp_call_function_from_idle(void);
@@ -2756,6 +2753,28 @@ static inline bool is_per_cpu_kthread(struct task_struct *p)
 extern void swake_up_all_locked(struct swait_queue_head *q);
 extern void __prepare_to_swait(struct swait_queue_head *q, struct swait_queue *wait);
 
+/* MuQSS compatibility functions */
+#ifdef CONFIG_64BIT
+static inline u64 read_sum_exec_runtime(struct task_struct *t)
+{
+       return t->se.sum_exec_runtime;
+}
+#else
+static inline u64 read_sum_exec_runtime(struct task_struct *t)
+{
+       u64 ns;
+       struct rq_flags rf;
+       struct rq *rq;
+
+       rq = task_rq_lock(t, &rf);
+       ns = t->se.sum_exec_runtime;
+       task_rq_unlock(rq, t, &rf);
+
+       return ns;
+}
+#endif
+#endif /* CONFIG_SCHED_MUQSS */
+
 #ifdef CONFIG_PREEMPT_DYNAMIC
 extern int preempt_dynamic_mode;
 extern int sched_dynamic_mode(const char *str);
diff --git a/kernel/sched/stats.h b/kernel/sched/stats.h
index dc218e9f4..df955cfe0 100644
--- a/kernel/sched/stats.h
+++ b/kernel/sched/stats.h
@@ -140,6 +140,15 @@ static inline void psi_sched_switch(struct task_struct *prev,
 	psi_task_switch(prev, next, sleep);
 }
 
+static inline void psi_task_tick(struct rq *rq)
+{
+        if (static_branch_likely(&psi_disabled))
+                return;
+
+        if (unlikely(rq->curr->in_memstall))
+                psi_memstall_tick(rq->curr, cpu_of(rq));
+}
+
 #else /* CONFIG_PSI */
 static inline void psi_enqueue(struct task_struct *p, bool wakeup) {}
 static inline void psi_dequeue(struct task_struct *p, bool sleep) {}
@@ -147,6 +156,7 @@ static inline void psi_ttwu_dequeue(struct task_struct *p) {}
 static inline void psi_sched_switch(struct task_struct *prev,
 				    struct task_struct *next,
 				    bool sleep) {}
+static inline void psi_task_tick(struct rq *rq) {}
 #endif /* CONFIG_PSI */
 
 #ifdef CONFIG_SCHED_INFO
-- 
2.32.0



